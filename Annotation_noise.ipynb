{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_training_set = pd.read_csv('/Users/khaals/Desktop/word2vec/radio/training/trial1/code_train.csv', sep='$')\n",
    "Df_training_set.dropna()\n",
    "len(Df_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I start by removing imitation noise for both the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLineInfo:\n",
    "    def __init__(self):\n",
    "        iHash = 0\n",
    "        iCounter= 0\n",
    "        strFileName = \"\"\n",
    "        strCodeLine = \"\"\n",
    "        strClassName=\"\"\n",
    "        strClassValue= \"\"\n",
    "        strTestName = \"\"\n",
    "        strPth=\"\"\n",
    "        iVerdict = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineDictionary = {}\n",
    "\n",
    "def addHashToLine():    \n",
    "    for i, strInputLine in Df_training_set.iterrows(): \n",
    "        strCodeLine = str(strInputLine['contents'])\n",
    "        iHash = int(hashlib.sha1(strCodeLine.encode('utf-8')).hexdigest(), 16) % (10 ** 8) \n",
    "        Df_training_set.set_value(i,'contents',strCodeLine)\n",
    "        Df_training_set.set_value(i,'hash',iHash)\n",
    "        \n",
    "def createDictionary():\n",
    "    iLineIndex = 0\n",
    "    for index, strInputLine in Df_training_set.iterrows():  \n",
    "            if iLineIndex != 0:            \n",
    "                lineObject = CLineInfo()\n",
    "                lineObject.iHash = int(strInputLine['hash'])\n",
    "                lineObject.strFileName = strInputLine['id']\n",
    "                lineObject.strCodeLine = strInputLine['contents']\n",
    "                lineObject.iVerdict = strInputLine['verdict']\n",
    "                lineObject.strClassName = strInputLine['class_name']\n",
    "                lineObject.strClassValue = strInputLine['class_value']\n",
    "                lineObject.strPath = strInputLine['path']\n",
    "                lineObject.strTestName = strInputLine['testName']\n",
    "                lineObject.iCounter = strInputLine['line']\n",
    "                # check if the line already exists in the dictionary\n",
    "                if lineObject.iHash in lineDictionary:\n",
    "                    old_line_verdict = lineDictionary[lineObject.iHash].iVerdict\n",
    "                    # check if the new occurrence has a different verdict and that lineObject has a verdict of 1, \n",
    "                    # if so, then we relabel the dictionary line by replacing it with the lineObject\n",
    "                    if (old_line_verdict != lineObject.iVerdict) and (lineObject.iVerdict == 1.0):\n",
    "                          lineDictionary[lineObject.iHash] = lineObject\n",
    "                    else:\n",
    "                        continue #do nothing and keep the lineObject as is in the dictionary\n",
    "                else:                \n",
    "                    lineDictionary[lineObject.iHash] = lineObject\n",
    "            iLineIndex += 1\n",
    "addHashToLine()\n",
    "createDictionary()\n",
    "len(lineDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFile = \"./code_test_no_noise.csv\"\n",
    "fOutputFile = io.open(outputFile, 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./code_test_no_noise.csv', mode='w') as csv_file:\n",
    "    header_names = ['id', 'line', 'contents', 'class_name', 'class_value', 'path' , 'testName', 'verdict'] #, 'verdict', 'hash'\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=header_names, quotechar='\"', \n",
    "                            quoting=csv.QUOTE_ALL, delimiter='$')\n",
    "    writer.writeheader()\n",
    "    for hashKey, oneLineObject in lineDictionary.items():\n",
    "        writer.writerow({'id': oneLineObject.strFileName, \n",
    "                         'line': str(oneLineObject.iCounter), \n",
    "                         'contents': oneLineObject.strCodeLine, \n",
    "                         'class_name': oneLineObject.strClassName, \n",
    "                         'class_value': oneLineObject.strClassValue,\n",
    "                         'testName' : oneLineObject.strTestName,\n",
    "                         'path': oneLineObject.strPath, \n",
    "                         'verdict': str(oneLineObject.iVerdict) }) #, 'verdict': str(oneLineObject.iVerdict),'hash': oneLineObject.iHash\n",
    "                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
